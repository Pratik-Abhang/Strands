{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efa50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the agent\n",
    "from strands import Agent\n",
    "from strands.models.openai import OpenAIModel  # For using OpenAI models\n",
    "from strands.tools import tool  # For creating tools the agent can use\n",
    "from langchain_community.vectorstores.faiss import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c526fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model = OpenAIModel(\n",
    "    client_args={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    },\n",
    "    # **model_config\n",
    "    model_id=\"gpt-4o\",\n",
    "    params={\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0f61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  # or whatever embedding model you used\n",
    "\n",
    "# Setup embedding model — same as when you built FAISS\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Persist directory where your FAISS index is saved\n",
    "PERSIST_DIR = \"vectordb_openai/\"  # change if your path is different\n",
    "\n",
    "# Define a Strands tool for retrieval\n",
    "@tool\n",
    "def aws_course_search(query: str, k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search AWS course PDF content (embedded in FAISS) for relevant text.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user’s search question.\n",
    "        k (int): Number of top similar chunks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        str: Joined text of the top-k relevant PDF chunks.\n",
    "    \"\"\"\n",
    "    # Load the FAISS vector store (with your embedding model)\n",
    "    vs = FAISS.load_local(PERSIST_DIR, embedding_model, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Perform similarity search\n",
    "    docs = vs.similarity_search(query, k=k)\n",
    "    \n",
    "    # Format the retrieved documents into a string\n",
    "    if not docs:\n",
    "        return \"No relevant information found in the AWS course material.\"\n",
    "    \n",
    "    output = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        # doc.metadata may have 'source', page, or any metadata you stored\n",
    "        src = doc.metadata.get(\"source\", \"unknown\")\n",
    "        page = doc.metadata.get(\"page\", None)\n",
    "        prefix = f\"Chunk {i+1} (Source: {src}\"\n",
    "        if page is not None:\n",
    "            prefix += f\", Page: {page}\"\n",
    "        prefix += \"):\\n\"\n",
    "        \n",
    "        output.append(prefix + doc.page_content)\n",
    "    \n",
    "    return \"\\n\\n\".join(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5623ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timezone as tz\n",
    "from typing import Any\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97006f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def current_time(timezone: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Get the current time in ISO 8601 format.\n",
    "\n",
    "    This tool returns the current date and time in ISO 8601 format (e.g., 2023-04-15T14:32:16.123456+00:00)\n",
    "    for the specified timezone. If no timezone is provided, the value from the DEFAULT_TIMEZONE\n",
    "    environment variable is used (defaults to 'UTC' if not set).\n",
    "\n",
    "    Args:\n",
    "        timezone (str, optional): The timezone to use (e.g., 'UTC', 'US/Pacific', 'Europe/London', 'Asia/Tokyo').\n",
    "            Defaults to environment variable DEFAULT_TIMEZONE ('UTC' if not set).\n",
    "\n",
    "    Returns:\n",
    "        str: The current time in ISO 8601 format.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an invalid timezone is provided.\n",
    "\n",
    "    Examples:\n",
    "        >>> current_time()  # Returns current time in default timezone (from DEFAULT_TIMEZONE or UTC)\n",
    "        '2023-04-15T14:32:16.123456+00:00'\n",
    "\n",
    "        >>> current_time(timezone=\"US/Pacific\")  # Returns current time in Pacific timezone\n",
    "        '2023-04-15T07:32:16.123456-07:00'\n",
    "    \"\"\"\n",
    "    # Get environment variables at runtime\n",
    "    default_timezone = os.getenv(\"DEFAULT_TIMEZONE\", \"UTC\")\n",
    "\n",
    "    # Use provided timezone or fall back to default\n",
    "    timezone = timezone or default_timezone\n",
    "\n",
    "    try:\n",
    "        if timezone.upper() == \"UTC\":\n",
    "            timezone_obj: Any = tz.utc\n",
    "        else:\n",
    "            timezone_obj = ZoneInfo(timezone)\n",
    "\n",
    "        return datetime.now(timezone_obj).isoformat()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error getting current time: {str(e)}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344c7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Strands Agent with this tool\n",
    "import uuid  # For generating unique IDs\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"AWS Course Assistant\",\n",
    "    model=model,\n",
    "    tools=[aws_course_search, current_time],\n",
    "    system_prompt=(\n",
    "        \"You are an assistant knowledgeable about the AWS course PDF content. \"\n",
    "        \"For any question related to the course, use the aws_course_search tool to look up relevant snippets.\"\n",
    "    ),\n",
    "    record_direct_tool_call = True,  # Record when tools are used\n",
    "    trace_attributes={\n",
    "        \"session.id\": str(uuid.uuid4()),  # Generate a unique session ID\n",
    "        \"user.id\": \"user-email-example@domain.com\",  # Example user ID\n",
    "        \"langfuse.tags\": [\n",
    "            \"Agent-SDK-Example\",\n",
    "            \"Strands-Project-Demo\",\n",
    "            \"Observability-Tutorial\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bd0926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: aws_course_search\n",
      "Amazon SageMaker is a fully managed service designed for developers and data scientists to build machine learning (ML) models. It simplifies the typically complex process of building, training, and deploying ML models by providing an end-to-end solution. Here are some key aspects of Amazon SageMaker:\n",
      "\n",
      "- **End-to-End ML Service**: SageMaker allows you to collect and prepare data, build and train machine learning models, and deploy these models while monitoring the performance of predictions.\n",
      "  \n",
      "- **Model Deployment & Inference**: It provides one-click deployment with automatic scaling and no servers to manage, which reduces overhead. It supports real-time predictions, serverless architecture, and can handle idle periods between traffic spikes, although it may tolerate more latency due to cold starts.\n",
      "\n",
      "SageMaker JumpStart, part of SageMaker, offers pre-built solutions and models to help accelerate the development process for common use cases.Agent: Amazon SageMaker is a fully managed service designed for developers and data scientists to build machine learning (ML) models. It simplifies the typically complex process of building, training, and deploying ML models by providing an end-to-end solution. Here are some key aspects of Amazon SageMaker:\n",
      "\n",
      "- **End-to-End ML Service**: SageMaker allows you to collect and prepare data, build and train machine learning models, and deploy these models while monitoring the performance of predictions.\n",
      "  \n",
      "- **Model Deployment & Inference**: It provides one-click deployment with automatic scaling and no servers to manage, which reduces overhead. It supports real-time predictions, serverless architecture, and can handle idle periods between traffic spikes, although it may tolerate more latency due to cold starts.\n",
      "\n",
      "SageMaker JumpStart, part of SageMaker, offers pre-built solutions and models to help accelerate the development process for common use cases.\n",
      "\n",
      "\n",
      "Tool #2: current_time\n",
      "The current time is 2025-11-25T15:49:29 UTC.Agent: The current time is 2025-11-25T15:49:29 UTC.\n",
      "\n",
      "\n",
      "Tool #3: aws_course_search\n",
      "Amazon Bedrock is a service that provides access to a wide range of Foundation Models (FM). Here are some key aspects of Amazon Bedrock:\n",
      "\n",
      "- **Foundation Models**: Bedrock allows you to access various foundation models. It makes a copy of the FM available only to you, which you can fine-tune with your own data. Importantly, none of your data is used to train the FM.\n",
      "\n",
      "- **Configuration and Security**: You can configure Bedrock to monitor configuration changes and keep API calls within a private VPC using PrivateLink.\n",
      "\n",
      "- **Data Sources**: Bedrock can connect to various data sources like Amazon S3, Confluence, Microsoft SharePoint, Salesforce, and web pages (including your website and social media feeds).\n",
      "\n",
      "- **Agents**: Bedrock supports agents that manage and perform multi-step tasks related to infrastructure provisioning, application deployment, and operational activities. These agents are configured to perform specific predefined action groups and can integrate with other systems and services.\n",
      "\n",
      "- **Retrieval-Augmented Generation (RAG)**: Bedrock also incorporates RAG, which involves retrieving information from specified data sources to enhance generation tasks.\n",
      "\n",
      "Overall, Amazon Bedrock provides a flexible and secure environment for utilizing and customizing foundation models while integrating with existing data and services.Agent: Amazon Bedrock is a service that provides access to a wide range of Foundation Models (FM). Here are some key aspects of Amazon Bedrock:\n",
      "\n",
      "- **Foundation Models**: Bedrock allows you to access various foundation models. It makes a copy of the FM available only to you, which you can fine-tune with your own data. Importantly, none of your data is used to train the FM.\n",
      "\n",
      "- **Configuration and Security**: You can configure Bedrock to monitor configuration changes and keep API calls within a private VPC using PrivateLink.\n",
      "\n",
      "- **Data Sources**: Bedrock can connect to various data sources like Amazon S3, Confluence, Microsoft SharePoint, Salesforce, and web pages (including your website and social media feeds).\n",
      "\n",
      "- **Agents**: Bedrock supports agents that manage and perform multi-step tasks related to infrastructure provisioning, application deployment, and operational activities. These agents are configured to perform specific predefined action groups and can integrate with other systems and services.\n",
      "\n",
      "- **Retrieval-Augmented Generation (RAG)**: Bedrock also incorporates RAG, which involves retrieving information from specified data sources to enhance generation tasks.\n",
      "\n",
      "Overall, Amazon Bedrock provides a flexible and secure environment for utilizing and customizing foundation models while integrating with existing data and services.\n",
      "\n",
      "How can I assist you further? If you have more questions or need additional information, feel free to ask!Agent: How can I assist you further? If you have more questions or need additional information, feel free to ask!\n",
      "\n",
      "It seems like your message is empty. If you have any questions or need assistance, please feel free to type them out. I'm here to help!Agent: It seems like your message is empty. If you have any questions or need assistance, please feel free to type them out. I'm here to help!\n",
      "\n",
      "If you have any questions or need assistance with AWS or any other topic, please feel free to ask. I'm here to help!Agent: If you have any questions or need assistance with AWS or any other topic, please feel free to ask. I'm here to help!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         user_query = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAsk about the AWS course: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         resp = agent(user_query)\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent:\u001b[39m\u001b[33m\"\u001b[39m, resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Strands\\strandsvenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Strands\\strandsvenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 5. Use the agent\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"Ask about the AWS course: \")\n",
    "        resp = agent(user_query)\n",
    "        print(\"Agent:\", resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f877b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strandsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
